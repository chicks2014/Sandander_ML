# -*- coding: utf-8 -*-
"""Santander__final_py.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zYlJIjmTtdpHEx4TBUtKJ3jVVjtBvJ-i

# Load libraries and dataset

---
"""

import pandas as pd
import numpy as np
from fancyimpute import KNN
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split 
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
import sklearn.metrics as metrics
import matplotlib.pyplot as plt
from sklearn.metrics import roc_auc_score
import seaborn as sns
import random
import os

# load data set
santander_train = pd.read_csv("https://s3-ap-southeast-1.amazonaws.com/edwisor-india-bucket/projects/data/DataN0106/train.csv")
santander_test = pd.read_csv("https://s3-ap-southeast-1.amazonaws.com/edwisor-india-bucket/projects/data/DataN0106/test.csv")

"""# Exploratory data analysis

---
"""

# view random 5 records from train dataset
print(santander_train.info())
santander_train.sample(5)

# view random 5 records from test dataset
print(santander_test.info())
santander_test.sample(5)

# view column names
santander_train.columns

# drop ID_code variable as it can't help in prediction
santander_train = santander_train.drop(columns = ['ID_code'])

# re-order columns - set target to last column
cols = santander_train.columns.tolist()
cols = cols[1:201] + cols[0:1]
santander_train = santander_train[cols]

# dataset info
santander_train.describe()

# histogram for few variables 
f, axes = plt.subplots(4, 5, figsize=(20, 12), sharex=True)
# first row
sns.distplot( santander_train['var_0'] , color="skyblue", ax=axes[0, 0])
sns.distplot( santander_train["var_1"] , color="olive", ax=axes[0, 1])
sns.distplot( santander_train["var_2"] , color="gold", ax=axes[0, 2])
sns.distplot( santander_train["var_3"] , color="teal", ax=axes[0, 3])
sns.distplot( santander_train["var_4"] , color="lightgreen", ax=axes[0, 4])
# second row
sns.distplot( santander_train['var_5'] , color="skyblue", ax=axes[1, 0])
sns.distplot( santander_train["var_6"] , color="olive", ax=axes[1, 1])
sns.distplot( santander_train["var_7"] , color="gold", ax=axes[1, 2])
sns.distplot( santander_train["var_8"] , color="teal", ax=axes[1, 3])
sns.distplot( santander_train["var_9"] , color="lightgreen", ax=axes[1, 4])
# third row
sns.distplot( santander_train['var_10'] , color="skyblue", ax=axes[2, 0])
sns.distplot( santander_train["var_11"] , color="olive", ax=axes[2, 1])
sns.distplot( santander_train["var_12"] , color="gold", ax=axes[2, 2])
sns.distplot( santander_train["var_13"] , color="teal", ax=axes[2, 3])
sns.distplot( santander_train["var_14"] , color="lightgreen", ax=axes[2, 4])
# fourth row
sns.distplot( santander_train['var_15'] , color="skyblue", ax=axes[3, 0])
sns.distplot( santander_train["var_16"] , color="olive", ax=axes[3, 1])
sns.distplot( santander_train["var_17"] , color="gold", ax=axes[3, 2])
sns.distplot( santander_train["var_18"] , color="teal", ax=axes[3, 3])
sns.distplot( santander_train["var_19"] , color="lightgreen", ax=axes[3, 4])

# take backup
santander_train_backup = santander_train
# santander_train = santander_train_backup

"""# Missing value analysis

---
"""

# view missing values count for each variable
total = santander_train.isnull().sum().sort_values(ascending=False)
percent = (santander_train.isnull().sum()/santander_train.isnull().count()).sort_values(ascending=False)
missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])
missing_data.head(10)

"""**In our dataset we don't have any missing values so no need to do further process for missing value analysis**

---

# Outlier Analysis

---
"""

# plot outliers for few variables
plt.figure(figsize=(16, 12))
santander_train.boxplot(column=['var_0', 'var_1', 'var_2','var_3','var_4', 'var_5', 'var_6','var_7','var_8', 'var_9','var_10'] , fontsize = 15, rot = 45)

# Detect outliers and replace with NA
def detect_outlier(df):
  for i in range(0, santander_train.shape[1] - 1):
    column_name = santander_train.columns[i]
    print(column_name)

    # find inter-quartile range
    q75, q25 = np.percentile(santander_train.iloc[:,i], [75,25])
    iqr = q75 - q25

    # find lower and upper fence
    lower_fence = round(q25 - (1.5*iqr),4)
    upper_fence = round(q75 + (1.5*iqr),4)
    print('lower_fence :', lower_fence)
    print('upper_fence :', upper_fence)

    # count outliers
    lower_outlier = santander_train.loc[santander_train[column_name] < lower_fence].shape[0]
    upper_outlier = santander_train.loc[santander_train[column_name] > upper_fence].shape[0]
    print('No of outlier in variable# ' + str(column_name) + " - " ,  lower_outlier + upper_outlier)

    # replace outlier with NA
    santander_train.loc[santander_train[column_name] < lower_fence, : column_name] = np.nan
    santander_train.loc[santander_train[column_name] > upper_fence, : column_name] = np.nan

# call detect outlier function
detect_outlier(santander_train)

# Now, we have missing values
# view missing values count against variable
total = santander_train.isnull().sum().sort_values(ascending=False)
percent = (santander_train.isnull().sum()/santander_train.isnull().count()).sort_values(ascending=False)
missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])

# takes only percent > 0 records
missing_data = missing_data[missing_data['Percent'] > 0]

# bar plot of missing value data
f, ax = plt.subplots(figsize=(25, 6))
plt.xticks(rotation='90')
sns.barplot(x=missing_data.index, y = missing_data['Percent'])
plt.xlabel('Features', fontsize=15)
plt.ylabel('Percent of missing values', fontsize=15)
plt.title('Percent missing data by feature', fontsize=15)
missing_data.head()

# impute with mean method
santander_train.fillna(santander_train.mean(), inplace=True)

# verify missing values are filled by mean method
santander_train.isnull().sum().sort_values(ascending=False)

"""# Feature selection"""

# Training set high correlations
df_train_corr = santander_train.corr().abs().unstack().sort_values(kind="quicksort", ascending=False).reset_index()
df_train_corr.rename(columns={"level_0": "Feature 1", "level_1": "Feature 2", 0: 'Correlation Coefficient'}, inplace=True)
df_train_corr.drop(df_train_corr.iloc[1::2].index, inplace=True)

df_train_corr_nd = df_train_corr.drop(df_train_corr[df_train_corr['Correlation Coefficient'] == 1.0].index)

# Training set high correlations
corr = df_train_corr_nd['Correlation Coefficient'] > 0.1
df_train_corr_nd[corr]

"""**In our dataset all the variables has a correlation coefficient < 0.08 which negligible**"""

# plot heatmap 
# Set width and height of plot
f,ax = plt.subplots(figsize=(60,40))

# Generate correlation matrix
corr = santander_train.corr()

# plot using seaborn library
sns.heatmap(corr, mask=np.zeros_like(corr,dtype=np.bool), cmap=sns.diverging_palette(20, 220, n=200) ,square=True, ax=ax)
## Give title. 
plt.title("Heatmap of all the Features", fontsize = 30);

"""**In our dataset all the variables has a correlation coefficient < 0.08 due to that we are getting almost same color through the heatmap**

# Handle imbalance data

---
"""

# view count of both class
target_count = santander_train.target.value_counts()
print('Class 0:', target_count[0])
print('Class 1:', target_count[1])

# barplot for view counts of both class
target_count.plot(kind='bar', title='Count (target)', color = "lightblue");

# spit data into dependent and independent variable
X = santander_train.values[:,0:200]
Y = santander_train.values[:,200]

# split data into four parts, train and test with dependent and independent
X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2, random_state = 1, stratify=Y)

# view data shape
print('Number of Training Examples = {}'.format(X_train.shape))
print('Number of Test Examples = {}\n'.format(X_test.shape))
print('Number of Training target  = {}'.format(y_train.shape))
print('Number of Test target = {}\n'.format(y_test.shape))

# Use SMOTE technique to balance dataset
smt = SMOTE()
X_train, y_train = smt.fit_sample(X_train, y_train)

# view shape of dataset
X_train.shape, y_train.shape, X_test.shape, y_test.shape

# verify balanced traget into train data
target_count = pd.DataFrame(y_train)[0].value_counts()
print('Class 0:', target_count[0])
print('Class 1:', target_count[1])

# barplot for view counts of both class
target_count.plot(kind='bar', title='Count (target)', color = "lightgreen");

"""---

# Feature scaling
"""

# Normalization function
def normalize_data(df) :
  for i in range(0, df.shape[1]) :
    df.iloc[:,i] = (df.iloc[:,i] - (df.iloc[:,i].min()))/((df.iloc[:,i].max()) - (df.iloc[:,i].min()))

# Data Normalization
df_x_train = pd.DataFrame(X_train)
df_x_test = pd.DataFrame(X_test)
normalize_data(df_x_train)
normalize_data(df_x_test)

# View normalize data
pd.DataFrame(X_train).describe()

# View data shape
print('Number of Training Examples = {}'.format(X_train.shape))
print('Number of Test Examples = {}\n'.format(X_test.shape))
print('Number of Training target = {}'.format(y_train.shape))
print('Number of Test target  = {}\n'.format(y_test.shape))

"""---

# **Model** **Development**


---
"""

# function for plot ROC 
def plot_roc(model) :
  # calculate the fpr and tpr for all thresholds of the classification
  probs = model.predict_proba(X_test)
  preds = probs[:,1]
  fpr, tpr, threshold = metrics.roc_curve(y_test, preds)
  roc_auc = metrics.auc(fpr, tpr)

  # plot ROC
  plt.title('Receiver Operating Characteristic')
  plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
  plt.legend(loc = 'lower right')
  plt.plot([0, 1], [0, 1],'r--')
  plt.xlim([0, 1])
  plt.ylim([0, 1])
  plt.ylabel('True Positive Rate')
  plt.xlabel('False Positive Rate')
  plt.show()

"""# **Logistic Regression**"""

# build logistic regression
logistic_regresssion_model = LogisticRegression()
logistic_regresssion_model.fit(X_train, y_train)

# predict logistic regression model
logit_predict = logistic_regresssion_model.predict(X_test)

# build confusion matrix
confusion_matrix_logit = pd.crosstab(y_test, logit_predict, rownames=['Actual'], colnames=['Predicted'])

# Let us save TN, TP, FN, FP
TP = confusion_matrix_logit.iloc[0,0]
FN = confusion_matrix_logit.iloc[0,1]
FP = confusion_matrix_logit.iloc[1,0]
TN = confusion_matrix_logit.iloc[1,1]

# check Accuracy
(TP + TN) * 100 / (TP+TN+FP+FN)

# view confusion matrix
confusion_matrix_logit

# FNR
(FN * 100)/(TP + FN)

# Recall
(TP * 100)/(TP + FN)

# Precision
(FP * 100)/(TP + FP)

# plot ROC
plot_roc(logistic_regresssion_model)

"""**Logistic Regression perforamce matrix**


*   Accuracy - 70.51
*   Misclassification -  21.07
*   Recall - 69.40
*   Precision - 96.94
*   FNR - 30.59
*   AUC - 0.84

# **Random forest**
"""

# Random Forest
random_forest_model = RandomForestClassifier(n_estimators = 150).fit(X_train, y_train)

random_forest_model

random_forest_prediction = random_forest_model.predict(X_test)

# build confusion matrix
confusion_matrix_random_forest = pd.crosstab(y_test, random_forest_prediction,  rownames=['Actual'], colnames=['Predicted'])

# Let us save TN, TP, FN, FP
TP = confusion_matrix_random_forest.iloc[0,0]
FN = confusion_matrix_random_forest.iloc[0,1]
FP = confusion_matrix_random_forest.iloc[1,0]
TN = confusion_matrix_random_forest.iloc[1,1]

# check Accuracy
(TP + TN) / (TP+TN+FP+FN) * 100

confusion_matrix_random_forest

# FNR
(FN * 100)/(TP + FN)

# Recall
(TP * 100)/(TP + FN)

# Precision
(TP * 100)/(TP + FP)

# plot ROC 
plot_roc(random_forest_model)

# Commented out IPython magic to ensure Python compatibility.
# fearure importance plot
feature_imp = pd.Series(random_forest_model.feature_importances_, index = santander_train.columns.values[0:200]).sort_values(ascending=False)

# take top 15 features 
f_imp = feature_imp[0:15]

# %matplotlib inline
# Creating a bar plot
sns.barplot(x=f_imp, y=f_imp.index)
# Add labels to your graph
plt.xlabel('Feature Importance Score')
plt.ylabel('Features')
plt.title("Visualizing Important Features")
plt.legend()
plt.figure(figsize=(15, 20))
plt.show()

"""**Random forest perforamce matrix**

```
number of trees 150
```


*   Accuracy - 85.39
*   Misclassification - 14.61
*   Recall - 94.09
*   Precision - 90.09
*   FNR - 5.90
*   AUC - 0.71

# **Naive bayes classifier**
"""

# Build Naive bayes
naive_bayes_model = GaussianNB().fit(X_train,y_train)

# predict naive bayes
naive_bayes_predict = naive_bayes_model.predict(X_test)

# build confusion matrix
confusion_matrix_naive_bayes = pd.crosstab(y_test, naive_bayes_predict, rownames=['Actual'], colnames=['Predicted'])

# Let us save TN, TP, FN, FP
TP = confusion_matrix_naive_bayes.iloc[0,0]
FN = confusion_matrix_naive_bayes.iloc[0,1]
FP = confusion_matrix_naive_bayes.iloc[1,0]
TN = confusion_matrix_naive_bayes.iloc[1,1]

# check Accuracy
((TP + TN) / (TP+TN+FP+FN)) * 100

# view confusion matrix
confusion_matrix_naive_bayes

# FNR
(FN * 100)/(TP + FN)

# Recall
(TP * 100) / (TP + FN)

# Precision
(TP * 100)/(TP + FP)

# plot ROC
plot_roc(naive_bayes_model)

"""**Naive Bayes perforamce matrix**


*   Accuracy - 83.27
*   Misclassification - 16.72
*   Recall - 91.53
*   Precision - 90.03
*   FNR - 8.46
*   AUC - 0.40
"""